# -*- coding: utf-8 -*-
"""DLLP3-AdiJayaSaputra.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yXz7TuhL2qi8HN2IhFjNtTQ9mIU89KRw
"""

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt

# ==========================================
# 1. PERSIAPAN DATA (Fashion MNIST)
# ==========================================
print("Sedang memuat dataset Fashion MNIST...")
# Muat data, x_test dan y_test adalah (10000, 28, 28) dan (10000,)
(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()

# Normalisasi data ke range [0, 1] dan tambah dimensi channel
fashion_mnist_data = np.concatenate([x_train, x_test], axis=0)
fashion_mnist_data = np.expand_dims(fashion_mnist_data, -1).astype("float32") / 255.0

# Parameter Global
LATENT_DIM = 2 # Dimensi latent 2D agar mudah divisualisasikan
EPOCHS = 15
BATCH_SIZE = 128

# Label mapping untuk plot
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# ==========================================
# 2. MEMBANGUN MODEL (AE & VAE)
# ==========================================

# --- Komponen Encoder Bersama ---
def build_encoder(latent_dim):
  encoder_inputs = keras.Input(shape=(28, 28, 1))
  x = layers.Flatten()(encoder_inputs)
  x = layers.Dense(256, activation="relu")(x)
  x = layers.Dense(128, activation="relu")(x)
  return encoder_inputs, x

# --- Komponen Decoder Bersama ---
def build_decoder(latent_dim):
  latent_inputs = keras.Input(shape=(latent_dim,))
  x = layers.Dense(128, activation="relu")(latent_inputs)
  x = layers.Dense(256, activation="relu")(x)
  x = layers.Dense(28 * 28, activation="sigmoid")(x)
  decoder_outputs = layers.Reshape((28, 28, 1))(x)
  return keras.Model(latent_inputs, decoder_outputs, name="decoder")

# --- A. Model Autoencoder Biasa (Standard AE) ---
encoder_inputs_ae, x_ae = build_encoder(LATENT_DIM)
z_ae = layers.Dense(LATENT_DIM, name="z_ae")(x_ae) # Latent vector langsung
encoder_ae = keras.Model(encoder_inputs_ae, z_ae, name="encoder_ae")
decoder_ae = build_decoder(LATENT_DIM)

ae_output = decoder_ae(encoder_ae(encoder_inputs_ae))
ae_model = keras.Model(encoder_inputs_ae, ae_output, name="autoencoder")
ae_model.compile(optimizer="adam", loss="mse")

# --- B. Model Variational Autoencoder (VAE) ---
# Layer Sampling (Reparameterization Trick)
class Sampling(layers.Layer):
  """Menggunakan (z_mean, z_log_var) untuk mensample z."""
  def call(self, inputs):
      z_mean, z_log_var = inputs
      batch = tf.shape(z_mean)[0]
      dim = tf.shape(z_mean)[1]
      epsilon = tf.keras.backend.random_normal(shape=(batch, dim))
      return z_mean + tf.exp(0.5 * z_log_var) * epsilon

encoder_inputs_vae, x_vae = build_encoder(LATENT_DIM)
z_mean = layers.Dense(LATENT_DIM, name="z_mean")(x_vae)
z_log_var = layers.Dense(LATENT_DIM, name="z_log_var")(x_vae)
z_vae = Sampling()([z_mean, z_log_var])
encoder_vae = keras.Model(encoder_inputs_vae, [z_mean, z_log_var, z_vae], name="encoder_vae")
decoder_vae = build_decoder(LATENT_DIM)

# Kelas VAE Custom untuk menangani KL Divergence Loss
class VAE(keras.Model):
  def __init__(self, encoder, decoder, **kwargs):
    super(VAE, self).__init__(**kwargs)
    self.encoder = encoder
    self.decoder = decoder
    self.total_loss_tracker = keras.metrics.Mean(name="total_loss")
    self.reconstruction_loss_tracker = keras.metrics.Mean(name="reconstruction_loss")
    self.kl_loss_tracker = keras.metrics.Mean(name="kl_loss")

  @property
  def metrics(self):
    return [self.total_loss_tracker, self.reconstruction_loss_tracker, self.kl_loss_tracker]

  def train_step(self, data):
    with tf.GradientTape() as tape:
      z_mean, z_log_var, z = self.encoder(data)
      reconstruction = self.decoder(z)
      # Reconstruction Loss (Binary Crossentropy karena pixel 0-1)
      reconstruction_loss = tf.reduce_mean(
          tf.reduce_sum(
              keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)
              )
          )
      # KL Divergence Loss
      kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))
      kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))
      total_loss = reconstruction_loss + kl_loss

      grads = tape.gradient(total_loss, self.trainable_weights)
      self.optimizer.apply_gradients(zip(grads, self.trainable_weights))

      self.total_loss_tracker.update_state(total_loss)
      self.reconstruction_loss_tracker.update_state(reconstruction_loss)
      self.kl_loss_tracker.update_state(kl_loss)
      return {
          "loss": self.total_loss_tracker.result(),
          "reconstruction_loss": self.reconstruction_loss_tracker.result(),
          "kl_loss": self.kl_loss_tracker.result(),
          }
  def call(self, inputs):
    z_mean, z_log_var, z = self.encoder(inputs)
    return self.decoder(z)

vae_model = VAE(encoder_vae, decoder_vae)
vae_model.compile(optimizer="adam")

# ==========================================
# 3. TRAINING MODEL
# ==========================================
print(f"\n--- Memulai Training Autoencoder Biasa ({EPOCHS} Epochs) ---")
ae_history = ae_model.fit(fashion_mnist_data, fashion_mnist_data, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)

print(f"\n--- Memulai Training VAE ({EPOCHS} Epochs) ---")
vae_history = vae_model.fit(fashion_mnist_data, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)

# ==========================================
# 4. VISUALISASI HASIL (Perbaikan dimulai dari sini)
# ==========================================
print("\nMembuat Visualisasi...")

# Setup plot figure besar: Menggunakan grid 3x3 secara logika
plt.figure(figsize=(18, 18))

# --- A. Visualisasi Distribusi Latent Space (VAE) ---
# Kita ambil sampel data test untuk plot
n_samples = 5000
test_images = x_test[:n_samples]
test_labels = y_test[:n_samples]
# Normalisasi dan tambah dimensi channel untuk input encoder VAE
test_images_input = np.expand_dims(test_images.astype("float32") / 255.0, -1)
z_mean_res, _, _ = vae_model.encoder.predict(test_images_input, verbose=0)

plt.subplot(3, 3, 1) # Posisikan di Baris 1, Kolom 1
plt.title("Latent Space Distribution (VAE)")
scatter = plt.scatter(z_mean_res[:, 0], z_mean_res[:, 1], c=test_labels, cmap="tab10", alpha=0.7, s=5)
plt.colorbar(scatter, ticks=range(10))
plt.xlabel("z[0]")
plt.ylabel("z[1]")
plt.grid(True, alpha=0.3)

# --- B. Latent Space Arithmetic (Grid Interpolation) ---
# Membangun manifold 2D dari latent space
def plot_latent_space(decoder, n=15, figsize=15, scale=2.0):
  # Buat grid linier dari koordinat latent
  grid_x = np.linspace(-scale, scale, n)
  grid_y = np.linspace(-scale, scale, n)
  image_width = 28
  image_height = 28
  image = np.zeros((image_height * n, image_width * n))

  for i, yi in enumerate(grid_x):
    for j, xi in enumerate(grid_y):
      z_sample = np.array([[xi, yi]])
      x_decoded = decoder.predict(z_sample, verbose=0)
      digit = x_decoded[0].reshape(image_width, image_height)

      # Masukkan ke grid gambar besar
      image[i * image_height: (i + 1) * image_height,
            j * image_width: (j + 1) * image_width] = digit

  return image # Corrected indentation

plt.subplot(3, 3, 2) # Posisikan di Baris 1, Kolom 2
plt.title("Latent Space Arithmetic (Interpolasi VAE)")
grid_img = plot_latent_space(decoder_vae, n=15, scale=3.0)
plt.imshow(grid_img, cmap="Greys_r")
plt.axis("off")
plt.xlabel("Transisi halus antar kategori")


# --- C. Perbandingan Rekonstruksi (Original vs AE vs VAE) ---
n_compare = 8
idx_choices = np.random.choice(len(x_test), n_compare)
# Ambil gambar asli (28x28)
orig_imgs_raw = x_test[idx_choices].astype("float32")
# Normalisasi dan tambah dimensi channel untuk input model
orig_imgs_input = np.expand_dims(orig_imgs_raw / 255.0, -1)

# Predict
ae_recon = ae_model.predict(orig_imgs_input, verbose=0)
vae_recon = vae_model.predict(orig_imgs_input, verbose=0)

# Fungsi bantuan untuk menggabungkan gambar dalam satu baris
def combine_images_row(images):
  n_imgs = images.shape[0]
  img_size = 28
  # Pastikan input sudah dinormalisasi ke [0, 1] dan hanya 2D (height x width)
  if images.ndim == 4:
    images = images.squeeze(-1) # Hapus dimensi channel

  row = np.zeros((img_size, img_size * n_imgs))
  for i in range(n_imgs):
    row[:, i*img_size:(i+1)*img_size] = images[i]
  return row # Corrected indentation

# Gabungkan gambar untuk setiap baris
# Catatan: Kita plot gambar asli yang belum dinormalisasi agar konsisten dengan tampilan Fashion MNIST data,
# tetapi karena colormap 'Greys_r' (hitam putih terbalik) digunakan,
# kita perlu memastikan rentang data di canvas sama (0-255 atau 0-1).
# Kita akan gunakan data yang sudah dinormalisasi (0-1) untuk semua, termasuk asli.
canvas_orig = combine_images_row(orig_imgs_raw / 255.0)
canvas_ae = combine_images_row(ae_recon)
canvas_vae = combine_images_row(vae_recon)

# Gabungkan ketiga baris rekonstruksi secara vertikal
canvas = np.concatenate([canvas_orig, canvas_ae, canvas_vae], axis=0)

plt.subplot(3, 1, 3) # Ambil seluruh lebar baris ke-3
plt.title("Perbandingan Rekonstruksi: Asli vs AE vs VAE", loc='center')
plt.axis("off") # Hilangkan sumbu X dan Y

plt.imshow(canvas, cmap="Greys_r")

# Tambahkan teks label di samping gambar
img_height = 28
text_pos_x = -30 # Posisi X agar berada di luar gambar
plt.text(text_pos_x, img_height * 0.5, "Original", fontsize=12, va='center')
plt.text(text_pos_x, img_height * 1.5, "Standard AE", fontsize=12, va='center')
plt.text(text_pos_x, img_height * 2.5, "VAE", fontsize=12, va='center')

# Pastikan layout rapih
plt.tight_layout()
plt.show()

print("Selesai. Grafik menampilkan:")
print("1. Kiri Atas: Sebaran data di latent space VAE (berwarna sesuai kelas).")
print("2. Kanan Atas: Grid interpolasi (Latent Arithmetic) menunjukkan transisi halus.")
print("3. Bawah: Perbandingan kualitas rekonstruksi dalam tiga baris yang jelas.")